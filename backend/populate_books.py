# populate_books_v2.py - VERSIÃ“N MEJORADA

import requests
import psycopg2
import time
import random
from psycopg2.extras import execute_values

# ============================================
# CONFIGURACIÃ“N
# ============================================
DATABASE_URL = "postgresql://library_user:Zqt906I5TLcpLwa59UJMN9WWVxE3sqDr@dpg-d6c3d5kr85hc73ds9t0g-a.oregon-postgres.render.com/library_db_l88q"
USER_AGENT = "LibraryPopulator/2.0 (usanaconisa@gmail.com)"
TARGET_BOOKS = 100000
BATCH_SIZE = 500  # Reducido para menos presiÃ³n en BD

# MÃ¡s idiomas
LANGUAGES = ['eng', 'spa', 'fre', 'ger', 'ita', 'por', 'tur', 'ara', 'jpn', 'rus', 'ara']

# MÃ¡s temas variados
TOPICS = [
    # FicciÃ³n
    "fiction", "science fiction", "fantasy", "mystery", "thriller",
    "romance", "adventure", "horror", "dystopian", "historical fiction",
    
    # No ficciÃ³n
    "history", "biography", "science", "technology", "philosophy",
    "psychology", "economics", "business", "self-help", "health",
    "cooking", "travel", "art", "music", "sports",
    
    # EspecÃ­ficos
    "programming", "mathematics", "physics", "chemistry", "biology",
    "politics", "religion", "education", "parenting", "gardening"
]

# ============================================
# FUNCIONES MEJORADAS
# ============================================

def fetch_books_from_openlibrary(topic, language, offset=0, limit=100, retries=10, backoff=3):
    """
    VersiÃ³n mejorada con:
    - MÃ¡s reintentos (10 en vez de 5)
    - Offset para paginaciÃ³n
    - LÃ­mite mÃ¡s bajo (100) para menos presiÃ³n
    - Backoff inicial mÃ¡s largo (3s)
    """
    url = "https://openlibrary.org/search.json"
    params = {
        "q": topic,
        "language": language,
        "limit": limit,
        "offset": offset,
        "fields": "key,title,author_name,first_publish_year,isbn,publisher,subject,language,cover_i"
    }
    headers = {'User-Agent': USER_AGENT}
    
    for attempt in range(retries):
        try:
            print(f"    [{topic}/{language}] Offset {offset}, intento {attempt+1}...")
            response = requests.get(url, params=params, headers=headers, timeout=45)
            
            if response.status_code == 500:
                wait_time = backoff * (2 ** attempt)  # Exponencial: 3, 6, 12, 24...
                print(f"    âš ï¸  Error 500. Esperando {wait_time}s antes de reintentar...")
                time.sleep(wait_time)
                continue
            
            response.raise_for_status()
            data = response.json()
            num_found = data.get('numFound', 0)
            docs = data.get('docs', [])
            print(f"    âœ… {len(docs)} libros obtenidos (total disponible: {num_found})")
            return docs, num_found
            
        except requests.exceptions.Timeout:
            print(f"    â±ï¸  Timeout. Reintentando...")
            time.sleep(backoff)
        except requests.exceptions.RequestException as e:
            print(f"    âŒ Error: {e}")
            if attempt == retries - 1:
                return [], 0
            time.sleep(backoff * (attempt + 1))
    
    return [], 0

def map_book_data(api_book, language):
    """Mapeo mejorado con validaciÃ³n"""
    # ISBN-13 preferido
    isbn_list = api_book.get('isbn', [])
    isbn = None
    for i in isbn_list:
        i_str = str(i).replace('-', '').replace(' ', '')
        if len(i_str) == 13 and i_str.isdigit():
            isbn = i_str
            break
    if not isbn and isbn_list:
        i_str = str(isbn_list[0]).replace('-', '').replace(' ', '')
        if i_str.isdigit() and len(i_str) >= 10:
            isbn = i_str
    
    if not isbn:
        return None  # Ignorar libros sin ISBN
    
    title = api_book.get('title', 'Sin tÃ­tulo')[:200]
    
    author_list = api_book.get('author_name', ['Unknown'])
    author = ', '.join(author_list[:3])[:200]  # Max 3 autores
    
    publisher_list = api_book.get('publisher', [])
    publisher = publisher_list[0][:200] if publisher_list else 'Unknown'
    
    pub_year = api_book.get('first_publish_year')
    
    # Copias aleatorias
    total = random.randint(1, 5)
    available = random.randint(0, total)
    
    subjects = api_book.get('subject', [])
    subject_str = ', '.join(subjects[:3]) if subjects else 'General'
    description = f"{subject_str}. From Open Library."[:500]
    
    # URL de portada
    cover_id = api_book.get('cover_i')
    cover_url = f"https://covers.openlibrary.org/b/id/{cover_id}-L.jpg" if cover_id else None
    
    # Mapear cÃ³digo de idioma
    lang_map = {
        'eng': 'en', 'spa': 'es', 'fre': 'fr', 'ger': 'de',
        'ita': 'it', 'por': 'pt', 'tur': 'tr', 'ara': 'ar',
        'jpn': 'ja', 'rus': 'ru', 'ara': 'ar'
    }
    lang_code = lang_map.get(language, 'en')
    
    return {
        'isbn': isbn,
        'title': title,
        'author': author,
        'publisher': publisher,
        'publication_year': pub_year,
        'total_copies': total,
        'available_copies': available,
        'description': description,
        'cover_image_url': cover_url,
        'language': lang_code
    }

def insert_books_batch(books_data):
    """InserciÃ³n con manejo de errores mejorado"""
    if not books_data:
        return 0
    
    try:
        conn = psycopg2.connect(DATABASE_URL)
        cur = conn.cursor()
        
        # Primero obtener una categorÃ­a por defecto
        cur.execute("SELECT id FROM categories LIMIT 1")
        default_cat = cur.fetchone()
        category_id = default_cat[0] if default_cat else None
        
        insert_query = """
            INSERT INTO books 
            (isbn, title, author, publisher, publication_year, 
             total_copies, available_copies, description, cover_image_url, language, category_id)
            VALUES %s
            ON CONFLICT (isbn) DO NOTHING
        """
        
        data_tuples = [
            (b['isbn'], b['title'], b['author'], b['publisher'],
             b['publication_year'], b['total_copies'], b['available_copies'],
             b['description'], b['cover_image_url'], b['language'], category_id)
            for b in books_data
        ]
        
        execute_values(cur, insert_query, data_tuples)
        inserted = cur.rowcount
        conn.commit()
        
        cur.close()
        conn.close()
        
        print(f"      ðŸ’¾ {inserted} libros nuevos insertados")
        return inserted
        
    except Exception as e:
        print(f"      âŒ Error BD: {e}")
        return 0

def get_current_count():
    """Obtener conteo actual de libros"""
    try:
        conn = psycopg2.connect(DATABASE_URL)
        cur = conn.cursor()
        cur.execute("SELECT COUNT(*) FROM books")
        count = cur.fetchone()[0]
        cur.close()
        conn.close()
        return count
    except:
        return 0

# ============================================
# PROGRAMA PRINCIPAL MEJORADO
# ============================================
if __name__ == "__main__":
    print("ðŸš€ POBLACIÃ“N DE BD - VERSIÃ“N MEJORADA")
    print(f"ðŸ“Š Objetivo: {TARGET_BOOKS:,} libros")
    print(f"ðŸ“š Estado actual: {get_current_count():,} libros\n")
    
    collected_books = []
    total_inserted = 0
    
    for lang in LANGUAGES:
        current_count = get_current_count()
        if current_count >= TARGET_BOOKS:
            print(f"\nðŸŽ‰ Â¡Objetivo alcanzado! {current_count:,} libros en BD")
            break
        
        print(f"\n{'='*60}")
        print(f"ðŸŒ IDIOMA: {lang.upper()}")
        print(f"{'='*60}")
        
        for topic in TOPICS:
            current_count = get_current_count()
            if current_count >= TARGET_BOOKS:
                break
            
            print(f"\n  ðŸ“– Tema: {topic}")
            
            # PaginaciÃ³n: obtener hasta 1000 libros por tema
            offset = 0
            while offset < 1000:
                docs, num_found = fetch_books_from_openlibrary(
                    topic, lang, offset=offset, limit=100
                )
                
                if not docs:
                    print(f"    â­ï¸  Sin mÃ¡s resultados")
                    break
                
                # Mapear libros
                for doc in docs:
                    mapped = map_book_data(doc, lang)
                    if mapped:
                        collected_books.append(mapped)
                
                # Insertar en lotes
                if len(collected_books) >= BATCH_SIZE:
                    inserted = insert_books_batch(collected_books)
                    total_inserted += inserted
                    collected_books = []
                    
                    current = get_current_count()
                    print(f"    ðŸ“Š Total en BD: {current:,} ({(current/TARGET_BOOKS*100):.1f}%)")
                
                offset += 100
                time.sleep(2)  # Pausa entre pÃ¡ginas
            
            time.sleep(3)  # Pausa entre temas
        
        time.sleep(5)  # Pausa entre idiomas
    
    # Insertar Ãºltimos libros
    if collected_books:
        insert_books_batch(collected_books)
    
    final_count = get_current_count()
    print(f"\n{'='*60}")
    print(f"âœ¨ COMPLETADO")
    print(f"ðŸ“š Total en BD: {final_count:,} libros")
    print(f"ðŸŽ¯ Progreso: {(final_count/TARGET_BOOKS*100):.1f}%")
    print(f"{'='*60}")
